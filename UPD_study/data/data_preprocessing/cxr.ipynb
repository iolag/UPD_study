{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "import glob \n",
    "import csv\n",
    "dataset_dir ='/home/ioannis/Thesis/Datasets/ChestXR/CheXpert-v1.0-small/'\n",
    "train_dir = '/home/ioannis/Thesis/Datasets/ChestXR/CheXpert-v1.0-small/train/patient*'\n",
    "val_dir = '/home/ioannis/Thesis/Datasets/ChestXR/CheXpert-v1.0-small/valid/patient*'\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Trainset:',len(glob.glob(train_dir)),'patients')\n",
    "print ('Validation Set:',len(glob.glob(val_dir)),'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Trainset:',len(glob.glob(train_dir+'/study*/view*.jpg')),'patients')\n",
    "print ('Validation Set:',len(glob.glob(val_dir)),'patients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open CSV. It contains all sample info as path_to_jpg|sex|age|frontal_or_lateral|class scores.  The first class is \"No finding\" indicating healthy sample. Positive label is 1. We will write 2 csvs that will contain the links of positives, one for each sex only for frontal (lateral has much lower number of samples so discard). We will keep study2 if it is done since the studies seem to have different appearences and would be worthwile to keep for a richer dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_keys = ['Path', 'Sex', 'Age', 'Frontal/Lateral', 'AP/PA', 'No Finding', \n",
    "                'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', \n",
    "                'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chest Posterior Anterior (PA) and Anterior Posterior (AP) radiographs. Should we take only one or the other? \n",
    "It would make sense to take both if they are of same left-right orientation. consider class imballance though --> seems balanced ~5k each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_dir + 'train.csv', newline='') as csvfile:\n",
    "    with open(dataset_dir + 'female_anomal_effusion_AP_no_sup_3419.txt', 'w', newline='') as female, open(dataset_dir + 'male_anomal_effusion_AP_no_sup_4036.txt', 'w', newline='') as male:\n",
    "\n",
    "        iterator = csv.DictReader(csvfile, delimiter=',', quotechar='|')    \n",
    "        count_m_f = [0,0]\n",
    "\n",
    "        for row in iterator:\n",
    "            \n",
    "            if row['Enlarged Cardiomediastinum'] != '1.0' and row['Frontal/Lateral'] == 'Frontal' and row['Age']>'18' and  row['AP/PA'] == 'PA' :\n",
    "                if row['Lung Opacity'] != '1.0' and row['Fracture'] != '1.0' and row['Pleural Other'] != '1.0' and  row['Pleural Effusion'] == '1.0' and row['Pneumothorax'] != '1.0':\n",
    "                    if row['Support Devices'] != '1.0':\n",
    "                        if row['Sex'] == 'Male':\n",
    "                            male.write(row['Path'] + \"\\n\")\n",
    "                            count_m_f[0] += 1\n",
    "\n",
    "                        elif row['Sex'] == 'Female':\n",
    "                            female.write(row['Path'] + \"\\n\")\n",
    "                            count_m_f[1] += 1   \n",
    "        \n",
    "count_m_f    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_dir + 'train.csv', newline='') as csvfile:\n",
    "    with open(dataset_dir + 'female_normal_train_AP_sup_5264.txt', 'w', newline='') as female, open(dataset_dir + 'male_normal_train_AP_sup_6134.txt', 'w', newline='') as male:\n",
    "\n",
    "        iterator = csv.DictReader(csvfile, delimiter=',', quotechar='|')    \n",
    "        count_m_f = [0,0]\n",
    "\n",
    "        for row in iterator:\n",
    "            \n",
    "            if row['No Finding'] == '1.0' and row['Frontal/Lateral'] == 'Frontal' and row['AP/PA'] == 'AP'  and row['Age']>'18':\n",
    "\n",
    "                if row['Sex'] == 'Male':\n",
    "                    male.write(row['Path'] + \"\\n\")\n",
    "                    count_m_f[0] += 1\n",
    "\n",
    "                elif row['Sex'] == 'Female':\n",
    "                    female.write(row['Path'] + \"\\n\")\n",
    "                    count_m_f[1] += 1   \n",
    "      \n",
    "count_m_f    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir ='/home/ioannis/Thesis/Datasets/ChestXR/'\n",
    "with  open(dataset_dir + 'male_normal_train.txt', 'r', newline='') as male:\n",
    "    paths = male.read().splitlines()\n",
    "    #print(paths)\n",
    "    for i in range(20):\n",
    "        \n",
    "        print (np.asarray(Image.open(data_dir+paths[i])).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some normal patients exist in valid set, 26 samples, just ignore those. Valid set is hand labeled instead of AI labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chexplanation preproc:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools import mask\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "with open('/datasets/Datasets/ChestXR/chexplanation_dataset/gt_segmentation_val.json') as json_file: \n",
    "    GT_data = json.load(json_file)\n",
    " \n",
    "#GT_data is a dict with keys of type 'patient64622_study1_view1_frontal'-->\n",
    "# (['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', 'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Support Devices']) -->\n",
    "# -->['size', 'counts'] which is a subdictionary that can be decoded by the mask.decode(x) function and output the binary segm image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools import mask\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "with open('/datasets/Datasets/ChestXR/chexplanation_dataset/gt_segmentation_val.json') as json_file: \n",
    "    GT_data = json.load(json_file)\n",
    " \n",
    "patient_list = list(GT_data.keys())\n",
    "\n",
    "for idx, patient in enumerate(patient_list):\n",
    "    if patient.split('_')[-1] == 'lateral':\n",
    "        patient_list.pop(idx)\n",
    "\n",
    "pathology_list = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', 'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Support Devices']\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "for i in patient_list:\n",
    "    #if 'Pleural Effusion' in GT_data[i].keys():\n",
    "    pathol_list = []\n",
    "    gt = []\n",
    "    paths = []\n",
    "    for j in range(len(pathology_list)):\n",
    "        img = mask.decode(GT_data[i][pathology_list[j]])\n",
    "        if not (img == np.zeros_like(img)).all():\n",
    "            pathol_list.append(pathology_list[j])\n",
    "\n",
    "    if len(pathol_list) == 1 and pathol_list[0] == 'Pleural Effusion'  :\n",
    "        gt.append(img)\n",
    "        patient_num, study, fr_lat = i.split(\"_\", 2)\n",
    "        path2 = '/datasets/Datasets/ChestXR/CheXpert-v1.0-small/valid/'+ patient_num +'/' + study+'/' + fr_lat+ '.jpg'\n",
    "        paths.append(path2)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathology_list = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', 'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Support Devices']\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "for i in patient_list:\n",
    "    #if 'Pleural Effusion' in GT_data[i].keys():\n",
    "    pathol_list = []\n",
    "    gt = []\n",
    "    paths = []\n",
    "    for j in range(len(pathology_list)):\n",
    "        img = mask.decode(GT_data[i][pathology_list[j]])\n",
    "        if not (img == np.zeros_like(img)).all():\n",
    "            pathol_list.append(pathology_list[j])\n",
    "\n",
    "    if len(pathol_list) == 1 and pathol_list[0] == 'Pleural Effusion'  :\n",
    "        gt.append(img)\n",
    "        patient_num, study, fr_lat = i.split(\"_\", 2)\n",
    "        path2 = '/datasets/Datasets/ChestXR/CheXpert-v1.0-small/valid/'+ patient_num +'/' + study+'/' + fr_lat+ '.jpg'\n",
    "        paths.append(path2)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_dir + 'valid.csv', newline='') as csvfile:\n",
    "        pa_m = 0\n",
    "        ap_m = 0\n",
    "        pa_f = 0\n",
    "        ap_f = 0\n",
    "        \n",
    "        iterator = csv.DictReader(csvfile, delimiter=',', quotechar='|')    \n",
    "        for row in iterator:\n",
    "            for pat in patient_list:\n",
    "                if pat.split('_')[0] in row['Path'].split('/') and 'study1' in row['Path'].split('/') and 'view1' in row['Path'].split('/')[-1].split('_'):\n",
    "                   if row['Frontal/Lateral'] == 'Frontal' and row['No Finding'] == '0.0' and row['Enlarged Cardiomediastinum'] != '1.0':\n",
    "                        if row['Sex'] == 'Female' and row['AP/PA'] == 'PA':\n",
    "                            pa_f+=1\n",
    "                        if row['Sex'] == 'Male' and row['AP/PA'] == 'PA':\n",
    "                            pa_m +=1\n",
    "                        if row['Sex'] == 'Female' and row['AP/PA'] == 'AP':\n",
    "                            ap_f +=1\n",
    "                        if row['Sex'] == 'Male' and row['AP/PA'] == 'AP':          \n",
    "                            ap_m +=1  \n",
    "print (pa_m, pa_f, ap_m, ap_f)       \n",
    "\n",
    "#chexplanation only has view1, study1 of no finding == '0.0' and some samples that have 0.0 to everything that the bellow code doesnt produce mask for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob.glob('/home/ioannis/Thesis/Datasets/ChestXR/CheXpert-v1.0-small/valid/patient*/*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pathologies (patient_data, patient_path):\n",
    "\n",
    "    patient_num, study, fr_lat = patient_path.split(\"_\", 2)\n",
    "    path = '/home/ioannis/Thesis/Datasets/ChestXR/chexplanation_dataset/cxr_valid/'+ patient_num +'/' + study+'/' + fr_lat+ '.jpg'\n",
    "    path2 = 'CheXpert-v1.0-small/valid/'+ patient_num +'/' + study+'/' + fr_lat+ '.jpg'\n",
    "    with open(dataset_dir + 'valid.csv', newline='') as csvfile:\n",
    "        iterator = csv.DictReader(csvfile, delimiter=',', quotechar='|')    \n",
    "        for row in iterator:\n",
    "            if row['Path'] == path2:\n",
    "                print(\"Conditions in sample:\", [i for i in csv_keys if row[i] == '1.0'], \", sex:\", row['Sex'])\n",
    "                    \n",
    "\n",
    "    pathology_list = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', 'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Support Devices']\n",
    "    pathol_list = []\n",
    "    count_pathologies = 0\n",
    "    for i in range(len(pathology_list)):\n",
    "        img = mask.decode(patient_data[pathology_list[i]])\n",
    "        if not (img == np.zeros_like(img)).all():\n",
    "            count_pathologies += 1\n",
    "            pathol_list.append(pathology_list[i])\n",
    "\n",
    "    plt.figure(figsize=(20,30))\n",
    "\n",
    "    for i in range(count_pathologies):\n",
    "        \n",
    "        img = mask.decode(patient_data[pathol_list[i]])\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.resize((256,256), PIL.Image.LANCZOS)\n",
    "        img = np.asarray(img)\n",
    "        plt.subplot(1,count_pathologies+1,i+1)\n",
    "        plt.title(pathol_list[i])\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    print(img.shape)\n",
    "    #plot real x-ray\n",
    "   \n",
    "    real_img = np.asarray(Image.open(path).resize((256,256), PIL.Image.LANCZOS))\n",
    "    plt.subplot(1,count_pathologies+1,count_pathologies+1)    \n",
    "    plt.title(\"CXR\")\n",
    "    plt.imshow(real_img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    print(real_img.shape)\n",
    "    #plt.tight_layout()  \n",
    "      \n",
    "    \n",
    "\n",
    "def total_segmentation (patient_data):\n",
    "    pathology_list = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', 'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion','Support Devices'] \n",
    "\n",
    "    for i in range(len(pathology_list)):\n",
    "        \n",
    "        img = mask.decode(patient_data[pathology_list[i]])\n",
    "        if (i == 0) :\n",
    "            total = np.zeros_like(img)\n",
    "        total += img\n",
    "    total [total != 0] = 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_segmentation_images (patient_data, patient_path):\n",
    "\n",
    "    patient_num, study, fr_lat = patient_path.split(\"_\", 2)\n",
    "    path = '/home/ioannis/Thesis/Datasets/ChestXR/chexplanation_dataset/cxr_valid/'+ patient_num +'/' + study+'/' + fr_lat+ '.jpg'\n",
    "    path2 = 'CheXpert-v1.0-small/valid/'+ patient_num +'/' + study+'/' + fr_lat+ '.jpg'\n",
    "    save_path = '/home/ioannis/Thesis/Datasets/ChestXR/chexplanation_dataset/cxr_valid/'+ patient_num +'/masks/' + fr_lat+ '_mask_'\n",
    "\n",
    "    if not os.path.exists('/home/ioannis/Thesis/Datasets/ChestXR/chexplanation_dataset/cxr_valid/'+ patient_num +'/masks/'):\n",
    "        os.makedirs('/home/ioannis/Thesis/Datasets/ChestXR/chexplanation_dataset/cxr_valid/'+ patient_num +'/masks/')\n",
    "    \n",
    "\n",
    "\n",
    "    with open(dataset_dir + 'valid.csv', newline='') as csvfile:\n",
    "        iterator = csv.DictReader(csvfile, delimiter=',', quotechar='|')    \n",
    "        for row in iterator:\n",
    "            if row['Path'] == path2:\n",
    "                pass\n",
    "                #print(\"Conditions in sample:\", [i for i in csv_keys if row[i] == '1.0'], \", sex:\", row['Sex'])\n",
    "                    \n",
    "\n",
    "    pathology_list = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', 'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Support Devices']\n",
    "\n",
    "    segmented_pathology_list = []\n",
    "\n",
    "    for pathology in pathology_list:\n",
    "        img = mask.decode(patient_data[pathology])\n",
    "        if not (img == np.zeros_like(img)).all():\n",
    "            segmented_pathology_list.append(pathology)\n",
    "\n",
    "    for seg in segmented_pathology_list:\n",
    "        \n",
    "        img = mask.decode(patient_data[seg])*255\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(save_path+seg+'.png')\n",
    "        #print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in patient_list:\n",
    "    \n",
    "    save_segmentation_images(GT_data[i], i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathology_list = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', #pathologies that segmentations exist for\n",
    "'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "\n",
    "with open(dataset_dir + 'valid.csv', newline='') as csvfile, open(dataset_dir + 'female_frontal_abnormal_validset.csv', 'w', newline='') as csvfile_female, open(dataset_dir + 'male_frontal_abnormal_validset.csv', 'w', newline='') as csvfile_male:\n",
    "\n",
    "    iterator = csv.DictReader(csvfile, delimiter=',', quotechar='|')    \n",
    "    count_m_f = [0,0]\n",
    "\n",
    "\n",
    "    writer_m = csv.writer(csvfile_male, delimiter=',',\n",
    "                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer_f = csv.writer(csvfile_female, delimiter=',',\n",
    "                        quotechar='|', quoting=csv.QUOTE_MINIMAL)  \n",
    "\n",
    "    for row in iterator:\n",
    "       \n",
    "        if row['No Finding'] != '1.0'  and row['Frontal/Lateral'] == 'Frontal' and row['Sex'] == 'Male' and row['Age'] > '18':\n",
    "            if row['Path'].split('/')[2] != 'patient64581' and row['Path'].split('/')[2] != 'patient64629':\n",
    "                writer_m.writerow([row['Path'],'chexplanation_dataset/cxr_valid/'+row['Path'].split('/')[2]+'/masks/', '1'])\n",
    "\n",
    "                count_m_f[0] += 1\n",
    "            \n",
    "        if row['No Finding'] != '1.0' and row['Frontal/Lateral'] == 'Frontal' and row['Sex'] == 'Female'and row['Age'] > '18': \n",
    "            if row['Path'].split('/')[2] != 'patient64581':\n",
    "                writer_f.writerow([row['Path'],'chexplanation_dataset/cxr_valid/'+row['Path'].split('/')[2]+'/masks/','1'])\n",
    "           \n",
    "            count_m_f[1] += 1   \n",
    "        if row['No Finding'] == '1.0' and row['Support Devices'] != '1.0' and row['Frontal/Lateral'] == 'Frontal' and row['Sex'] == 'Male' and row['Age'] > '18':\n",
    "            \n",
    "            writer_m.writerow([row['Path'], 'chexplanation_dataset/cxr_valid/'+row['Path'].split('/')[2]+'/masks/', '0'])\n",
    "      \n",
    "            \n",
    "           \n",
    "            \n",
    "        if row['No Finding'] == '1.0' and row['Support Devices'] != '1.0' and row['Frontal/Lateral'] == 'Frontal' and row['Sex'] == 'Female'and row['Age'] > '18': \n",
    "            writer_f.writerow([row['Path'], 'chexplanation_dataset/cxr_valid/'+row['Path'].split('/')[2]+'/masks/','0'] )\n",
    "           \n",
    "            \n",
    "        \n",
    "print(count_m_f)\n",
    "#print( abnormal_samples, len(abnormal_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathology_list = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', #pathologies that segmentations exist for\n",
    "'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "\n",
    "with open(dataset_dir + 'valid.csv', newline='') as csvfile, open(dataset_dir + 'female_frontal_abnormal_validset.csv', 'w', newline='') as csvfile_female, open(dataset_dir + 'male_frontal_abnormal_validset.csv', 'w', newline='') as csvfile_male:\n",
    "\n",
    "    iterator = csv.DictReader(csvfile, delimiter=',', quotechar='|')    \n",
    "    count_m_f = [0,0]\n",
    "\n",
    "\n",
    "    writer_m = csv.writer(csvfile_male, delimiter=',',\n",
    "                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer_f = csv.writer(csvfile_female, delimiter=',',\n",
    "                        quotechar='|', quoting=csv.QUOTE_MINIMAL)  \n",
    "\n",
    "    for row in iterator:\n",
    "       \n",
    "        if row['Path'].split('/')[2] == 'patient64629':\n",
    "            print (row)\n",
    "            \n",
    "\n",
    "           \n",
    "            \n",
    "        \n",
    "print(count_m_f)\n",
    "#print( abnormal_samples, len(abnormal_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_keys = ['Path', 'Sex', 'Age', 'Frontal/Lateral', 'AP/PA', 'No Finding', \n",
    "                'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', \n",
    "                'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion',\n",
    "                 'Pleural Other', 'Fracture', 'Support Devices']\n",
    "\n",
    "pathology_list = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', #pathologies that segmentations exist for\n",
    "'Airspace Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "dataset_dir ='/home/ioannis/Thesis/Datasets/'\n",
    "with open(os.path.join(dataset_dir,'ChestXR/CheXpert-v1.0-small/') + 'train.csv', newline='', mode='r') as csvfile:\n",
    "\n",
    "    iterator = csv.DictReader(csvfile, delimiter=',', quotechar='|')    \n",
    "\n",
    "    count = 0\n",
    "   \n",
    "    for row in iterator:\n",
    "       \n",
    "        if row['Enlarged Cardiomediastinum'] != '1.0' and row['Frontal/Lateral'] == 'Frontal' and row['Sex'] == 'Female':\n",
    "            if row['Age']>'18' and row['No Finding'] == '1.0' :\n",
    "                count += 1\n",
    "             \n",
    "            \n",
    "                \n",
    " #9624 ,7238      \n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these ground truths where produced with the context of saliency--> the doctors are annotating the region of interest ROI corresponding to the lession at hand (similart to LAG datgaset), and according to 20 page of paper these have huge inter expert variance and depends of context of different countries on how to define these anomalies\n",
    "\n",
    "it should not be used for the problem of pixel level detection but still trying it would be intresting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pneumonothorax dataset: I cant find anywhere detailed info about the dataset. I dont know if the diagnosis is detailed and no other lessions exist in the images, healthy or pneumono positive. Cant trust healthy or positive samples. As seem in Chexpert dataset, pneumonothorax segmented samples  come with other lessions so the per pixel \n",
    "evaluation on pneumonothorax masks will not be accurate. But we can try evaluating nevertheless and see results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data\n",
    "https://www.kaggle.com/juliaelliott/siim-reference-model\n",
    "https://www.kaggle.com/iafoss/data-repack-and-image-statistics\n",
    "https://www.kaggle.com/onealbao/dicom-to-jpeg-conversion-kernel\n",
    "https://www.kaggle.com/seesee/siim-train-test\n",
    "https://www.kaggle.com/retyidoro/eda-of-pneumothorax-dataset\n",
    "https://www.kaggle.com/maxwell110/dive-into-dicom-datasets\n",
    "https://www.kaggle.com/abhishek/move-all-dicom-images-to-train-and-test-folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ony why stanford set is better than chestxray14\n",
    "\n",
    "https://lukeoakdenrayner.wordpress.com/2017/11/18/quick-thoughts-on-chestxray14-performance-claims-and-clinical-tasks/\n",
    "https://lukeoakdenrayner.wordpress.com/2017/12/18/the-chestxray14-dataset-problems/\n",
    "https://lukeoakdenrayner.wordpress.com/2019/02/25/half-a-million-x-rays-first-impressions-of-the-stanford-and-mit-chest-x-ray-datasets/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
